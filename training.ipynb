{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WPILib ML Training Notebook\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "By using this notebook, you can train a TensorFlow Lite model for use on a Raspberry Pi and Google Coral USB Accelerator. We've designed this process to be as simple as possible. If you find an issue with this notebook, please create a new issue report on our [GitHub page](https://github.com/wpilibsuite/CoralSagemaker), where you downloaded this notebook.\n",
    "\n",
    "Complete instructions on how to train a model can be found [here](https://docs.wpilib.org/en/latest/docs/software/examples-tutorials/machine-learning/index.html).\n",
    "\n",
    "The code below will take longer depending on your value for 'epochs'. A higher value will take longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-03 05:28:29 Starting - Starting the training job...\n",
      "2020-04-03 05:28:30 Starting - Launching requested ML instances......\n",
      "2020-04-03 05:29:43 Starting - Preparing the instances for training...\n",
      "2020-04-03 05:30:20 Downloading - Downloading input data...\n",
      "2020-04-03 05:30:31 Training - Downloading the training image......\n",
      "2020-04-03 05:31:52 Training - Training image download completed. Training in progress.\u001b[34m.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/tensorflow/models/research/json_to_csv.py\", line 37, in <module>\n",
      "    make_csv(\"/opt/ml/input/data/training/tmp/train.csv\", train_jsons)\n",
      "  File \"/tensorflow/models/research/json_to_csv.py\", line 27, in make_csv\n",
      "    line = json.loads(file.readlines()[0])\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 355, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\u001b[0m\n",
      "\u001b[34mjson.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/tensorflow/models/research/generate_tfrecord.py\", line 102, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
      "    _sys.exit(main(argv))\n",
      "  File \"/tensorflow/models/research/generate_tfrecord.py\", line 88, in main\n",
      "    labels = get_labels()\n",
      "  File \"/tensorflow/models/research/parse_meta.py\", line 10, in get_labels\n",
      "    return [label[\"title\"] for label in json.loads(meta.readlines()[0])[\"classes\"]]\n",
      "  File \"/usr/lib/python2.7/json/__init__.py\", line 339, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python2.7/json/decoder.py\", line 364, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python2.7/json/decoder.py\", line 380, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\u001b[0m\n",
      "\u001b[34mValueError: Expecting object: line 1 column 2 (char 1)\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/tensorflow/models/research/generate_tfrecord.py\", line 102, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
      "    _sys.exit(main(argv))\n",
      "  File \"/tensorflow/models/research/generate_tfrecord.py\", line 86, in main\n",
      "    examples = pd.read_csv(args.input_csv)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.py\", line 678, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.py\", line 440, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.py\", line 787, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.py\", line 1014, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.py\", line 1708, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 384, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 695, in pandas._libs.parsers.TextReader._setup_parser_source\u001b[0m\n",
      "\u001b[34mIOError: File ./tmp/eval.csv does not exist\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/tensorflow/models/research/parse_meta.py\", line 17, in <module>\n",
      "    for i, label in enumerate(get_labels()):\n",
      "  File \"/tensorflow/models/research/parse_meta.py\", line 10, in get_labels\n",
      "    return [label[\"title\"] for label in json.loads(meta.readlines()[0])[\"classes\"]]\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 355, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\u001b[0m\n",
      "\u001b[34mjson.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\u001b[0m\n",
      "\u001b[34mDownloading model.\u001b[0m\n",
      "\u001b[34mRecords generated.\u001b[0m\n",
      "\u001b[34mHyperparameters parsed.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"accuracy.py\", line 59, in <module>\n",
      "    main()\n",
      "  File \"accuracy.py\", line 30, in main\n",
      "    checkpoint_max = max(checkpoint_nbs)\u001b[0m\n",
      "\u001b[34mValueError: max() arg is an empty sequence\u001b[0m\n",
      "\u001b[34mBeginning training on Docker image.\u001b[0m\n",
      "\u001b[34mcp: cannot stat './learn/models/output_tflite_graph.tflite': No such file or directory\u001b[0m\n",
      "\u001b[34mConverting checkpoint to tflite.\u001b[0m\n",
      "\u001b[34mrm: cannot remove '/opt/ml/model/output_tflite_graph_edgetpu.log': No such file or directory\u001b[0m\n",
      "\u001b[34mmv: cannot stat '/opt/ml/model/output_tflite_graph_edgetpu.tflite': No such file or directory\u001b[0m\n",
      "\u001b[34mCompiling model for Edge TPU\u001b[0m\n",
      "\n",
      "2020-04-03 05:32:23 Uploading - Uploading generated training model\n",
      "2020-04-03 05:32:23 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job wpi-cpu-2020-04-03-05-28-28-872: Failed. Reason: AlgorithmError: Exit Code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7e979779716c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Change this bucket if you want to train with your own data. The WPILib bucket contains thousands of high quality labeled images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# s3://wpilib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://frc-8077-2020-powercells-bucket-east\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2613\u001b[0m                 ),\n\u001b[1;32m   2614\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2615\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2616\u001b[0m             )\n\u001b[1;32m   2617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job wpi-cpu-2020-04-03-05-28-28-872: Failed. Reason: AlgorithmError: Exit Code: 1"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "instance_type = 'ml.m5.xlarge'\n",
    "algorithm_name = 'wpi-cpu'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Hyperparameters:\n",
    "    epochs -> int: number of training steps. Training time is proportional to this number. default = 1000\n",
    "    batch_size -> int: size of a batch of training images. default = 32\n",
    "    train_max_run -> int: max seconds a training job can run for. default = 43200\n",
    "\"\"\"\n",
    "hyperparameters = {'epochs': 1000,\n",
    "                   'batch_size': 32}\n",
    "\n",
    "ecr_image = \"249838237784.dkr.ecr.us-east-1.amazonaws.com/{}:latest\".format(algorithm_name)\n",
    "\n",
    "# The estimator object, using our notebook, training instance, the ECR image, and the specified training steps\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type=instance_type,\n",
    "                      image_name=ecr_image,\n",
    "                      hyperparameters=hyperparameters,\n",
    "                      train_max_run=43200)\n",
    "\n",
    "# Change this bucket if you want to train with your own data. The WPILib bucket contains thousands of high quality labeled images.\n",
    "# s3://wpilib\n",
    "estimator.fit(\"s3://frc-8077-2020-powercells-bucket-east\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "You can download your trained model after the above step tells you \"Training job completed\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
